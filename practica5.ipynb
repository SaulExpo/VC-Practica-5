{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37b899bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Usuario\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "import shutil\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "from deepface import DeepFace\n",
    "\n",
    "# Definir función para cargar PNGs\n",
    "def load_image(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    return img\n",
    "\n",
    "def overlay_image(bg, overlay, x, y, scale=1.0):\n",
    "    if overlay is None:\n",
    "        return bg\n",
    "\n",
    "    h, w = overlay.shape[:2]\n",
    "    new_w, new_h = int(w * scale), int(h * scale)\n",
    "    overlay = cv2.resize(overlay, (new_w, new_h))\n",
    "\n",
    "    orig_x, orig_y = x, y\n",
    "\n",
    "    overlay_x1 = max(0, -orig_x)\n",
    "    overlay_y1 = max(0, -orig_y)\n",
    "\n",
    "    x = max(0, orig_x)\n",
    "    y = max(0, orig_y)\n",
    "\n",
    "    overlay_visible_w = min(new_w - overlay_x1, bg.shape[1] - x)\n",
    "    overlay_visible_h = min(new_h - overlay_y1, bg.shape[0] - y)\n",
    "\n",
    "    if overlay_visible_w <= 0 or overlay_visible_h <= 0:\n",
    "        return bg \n",
    "\n",
    "    overlay_crop = overlay[overlay_y1:overlay_y1+overlay_visible_h,\n",
    "                           overlay_x1:overlay_x1+overlay_visible_w]\n",
    "\n",
    "    if overlay.shape[2] == 4:\n",
    "        alpha = overlay_crop[:, :, 3] / 255.0\n",
    "        for c in range(3):\n",
    "            bg[y:y+overlay_visible_h, x:x+overlay_visible_w, c] = \\\n",
    "                alpha * overlay_crop[:, :, c] + \\\n",
    "                (1 - alpha) * bg[y:y+overlay_visible_h, x:x+overlay_visible_w, c]\n",
    "    else:\n",
    "        bg[y:y+overlay_visible_h, x:x+overlay_visible_w] = overlay_crop\n",
    "\n",
    "    return bg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63769df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Descargar dataset FER (emociones)\n",
    "dataset_path = kagglehub.dataset_download(\"ananthu017/emotion-detection-fer\")\n",
    "\n",
    "base = dataset_path\n",
    "\n",
    "# Crear el modelo YOLOv8 pequeño para clasificación\n",
    "model = YOLO(\"yolov8s-cls.pt\")\n",
    "\n",
    "model.train(\n",
    "    data=base,\n",
    "    epochs=12,\n",
    "    imgsz=128,\n",
    "    batch=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1f683b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelo entrenado\n",
    "model = YOLO(\"runs/classify/train/weights/best.pt\")\n",
    "\n",
    "# Detector de rostros\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "\n",
    "smile = load_image(\"assets/smile.png\")\n",
    "cloud = load_image(\"assets/rain.png\")\n",
    "smoke = load_image(\"assets/smoke.png\")\n",
    "sweat = load_image(\"assets/sweat.png\")\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Bucle de procesamiento de video\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame, (640, 480))\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face = frame[y:y+h, x:x+w]\n",
    "        face_resized = cv2.resize(face, (224, 224))\n",
    "        result = model(face_resized, verbose=False)[0]\n",
    "        emotion_id = result.probs.top1\n",
    "        emotion = result.names[emotion_id]\n",
    "\n",
    "        cv2.putText(frame, emotion, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "\n",
    "         # Efectivos según emoción\n",
    "        if emotion == \"happy\" and smile is not None:\n",
    "            scale_factor = w / 4000 \n",
    "            pos_x = x + w//2 - int(smile.shape[1] * scale_factor / 2)\n",
    "            pos_y = y - int(smile.shape[0] * scale_factor) - 10\n",
    "            frame = overlay_image(frame, smile, pos_x, pos_y, scale=scale_factor)\n",
    "\n",
    "        elif emotion == \"sad\" and cloud is not None:\n",
    "            scale_factor = w / 600\n",
    "            pos_x = x + w//2 - int(cloud.shape[1] * scale_factor / 2)\n",
    "            pos_y = y - int(cloud.shape[0] * scale_factor) - 20\n",
    "            frame = overlay_image(frame, cloud, pos_x, pos_y, scale=scale_factor)\n",
    "\n",
    "        elif emotion == \"angry\" and smoke is not None:\n",
    "            scale_factor = w / 2500\n",
    "            flipped_smoke = cv2.flip(smoke, 1)\n",
    "            ear_height = y + int(h * 0.05)\n",
    "            frame = overlay_image(frame, flipped_smoke, x - int(30 * scale_factor)-150, ear_height, scale=scale_factor)\n",
    "            frame = overlay_image(frame, smoke, x + w - int(30 * scale_factor), ear_height, scale=scale_factor)\n",
    "\n",
    "        elif emotion == \"surprised\":\n",
    "            cv2.putText(frame, \"!\", (x + w//2, y - 40), cv2.FONT_HERSHEY_SIMPLEX, 3, (0,0,255), 6)\n",
    "\n",
    "        elif emotion == \"fearful\" and sweat is not None:\n",
    "            scale_factor = w / 6000\n",
    "            frame = overlay_image(frame, sweat, x + int(w*0.1), y + int(h*0.1), scale=scale_factor)\n",
    "            frame = overlay_image(frame, sweat, x + int(w*0.55), y + int(h*0.1), scale=scale_factor)\n",
    "\n",
    "        elif emotion == \"neutral\":\n",
    "            overlay = frame.copy()\n",
    "            overlay[:] = (100, 100, 100)\n",
    "            frame = cv2.addWeighted(overlay, 0.25, frame, 0.75, 0)\n",
    "\n",
    "    cv2.imshow(\"Emociones\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657376e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_hat = load_image(\"assets/top_hat.png\")\n",
    "monocle = load_image(\"assets/monocle.png\")\n",
    "mustache = load_image(\"assets/mustache.png\")\n",
    "\n",
    "\n",
    "# Filtro de estática \n",
    "def add_static(frame, amount=0.12):\n",
    "    noise = np.random.randint(0, 255, (frame.shape[0], frame.shape[1]), dtype=np.uint8)\n",
    "    noise = cv2.cvtColor(noise, cv2.COLOR_GRAY2BGR)\n",
    "    return cv2.addWeighted(frame, 1 - amount, noise, amount, 0)\n",
    "\n",
    "\n",
    "\n",
    "# Bucle de procesamiento de video\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame, (640, 480))\n",
    " \n",
    "    # Deepface\n",
    "    detections = DeepFace.extract_faces(\n",
    "        img_path=frame,\n",
    "        detector_backend='opencv', \n",
    "        enforce_detection=False\n",
    "    )\n",
    "\n",
    "    if len(detections) > 0:\n",
    "        face_obj = detections[0]\n",
    "\n",
    "        fa = face_obj[\"facial_area\"]\n",
    "        x = int(fa[\"x\"])\n",
    "        y = int(fa[\"y\"])\n",
    "        w = int(fa[\"w\"])\n",
    "        h = int(fa[\"h\"])\n",
    "\n",
    "\n",
    "        # Sombrero de copa\n",
    "        hat_scale = w / 200\n",
    "        hat_x = x + w//2 - int(top_hat.shape[1] * hat_scale / 2)\n",
    "        hat_y = y - int(top_hat.shape[0] * hat_scale) +10\n",
    "        frame = overlay_image(frame, top_hat, hat_x, hat_y, hat_scale)\n",
    "\n",
    "        # Monóculo\n",
    "        if monocle is not None:\n",
    "            mono_scale = w / 2000\n",
    "            eye_x = x + int(w * 0.68)\n",
    "            eye_y = y + int(h * 0.52)\n",
    "\n",
    "            mono_x = eye_x - int(monocle.shape[1] * mono_scale / 2)\n",
    "            mono_y = eye_y - int(monocle.shape[0] * mono_scale / 2)\n",
    "\n",
    "            frame = overlay_image(frame, monocle, mono_x, mono_y, mono_scale)\n",
    "\n",
    "        # Bigote\n",
    "        if mustache is not None:\n",
    "            must_scale = w / 1500\n",
    "\n",
    "            must_y = y + int(h * 0.33)\n",
    "            must_x = x + w//2 - int(mustache.shape[1] * must_scale / 2)\n",
    "\n",
    "            frame = overlay_image(frame, mustache, must_x, must_y, must_scale)\n",
    "\n",
    "\n",
    "    # Fitro blanco y negro\n",
    "    old_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    old_frame = cv2.cvtColor(old_frame, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Añadir estática\n",
    "    old_frame = add_static(old_frame, amount=0.15)\n",
    "\n",
    "    cv2.imshow(\"Hombre Monopoly\", old_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
